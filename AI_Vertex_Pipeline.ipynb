{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Vertex Pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snvssk/data298A/blob/saidev/AI_Vertex_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2T4zN58itdrR"
      },
      "source": [
        "This notebook is part of a article about Vertex AI Pipelines. If you want to get more background information head over to the article. \n",
        "\n",
        "https://blog.doit-intl.com/google-vertex-ai-the-easiest-way-to-run-ml-pipelines-3a41c5ed153"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqB5XvP-U3Sn"
      },
      "source": [
        "# Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5UmtuvhYixkz",
        "outputId": "ff5996bc-c85d-49f5-ca30-1501cc3ed634"
      },
      "source": [
        "!pip install google-cloud-aiplatform==1.7.1 --upgrade\n",
        "!pip install google-cloud-pipeline-components==0.2.0 --upgrade\n",
        "!pip install kfp==1.8.8 --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-cloud-aiplatform==1.7.1\n",
            "  Downloading google_cloud_aiplatform-1.7.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core[grpc]<3.0.0dev,>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform==1.7.1) (1.31.6)\n",
            "Collecting proto-plus>=1.10.1\n",
            "  Downloading proto_plus-1.20.5-py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 2.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform==1.7.1) (21.3)\n",
            "Collecting google-cloud-storage<2.0.0dev,>=1.32.0\n",
            "  Downloading google_cloud_storage-1.44.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 37.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform==1.7.1) (1.21.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (2022.1)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (3.17.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (1.56.2)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (1.35.0)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (1.15.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (1.46.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (4.2.4)\n",
            "Requirement already satisfied: google-resumable-media!=0.4.0,<0.5.0dev,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (0.4.1)\n",
            "Requirement already satisfied: google-cloud-core<2.0dev,>=1.0.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (1.0.3)\n",
            "Collecting google-cloud-core<2.0dev,>=1.0.3\n",
            "  Downloading google_cloud_core-1.7.2-py2.py3-none-any.whl (28 kB)\n",
            "Collecting google-cloud-storage<2.0.0dev,>=1.32.0\n",
            "  Downloading google_cloud_storage-1.43.0-py2.py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 51.9 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.42.3-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 47.1 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.42.2-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 36.9 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.42.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 63.7 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.42.0-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 43.6 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.41.1-py2.py3-none-any.whl (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 56.8 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.41.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 37.1 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.40.0-py2.py3-none-any.whl (104 kB)\n",
            "\u001b[K     |████████████████████████████████| 104 kB 46.4 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.39.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 10.4 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.38.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 64.5 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.37.1-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 46.1 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.37.0-py2.py3-none-any.whl (103 kB)\n",
            "\u001b[K     |████████████████████████████████| 103 kB 48.6 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.36.2-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 4.9 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.36.1-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 4.6 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.36.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.0 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.35.1-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 5.6 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.35.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 4.2 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.34.0-py2.py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 2.6 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.33.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 10.0 MB/s \n",
            "\u001b[?25h  Downloading google_cloud_storage-1.32.0-py2.py3-none-any.whl (92 kB)\n",
            "\u001b[K     |████████████████████████████████| 92 kB 8.7 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of google-cloud-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-cloud-core<2.0dev,>=1.0.3\n",
            "  Downloading google_cloud_core-1.7.1-py2.py3-none-any.whl (28 kB)\n",
            "  Downloading google_cloud_core-1.7.0-py2.py3-none-any.whl (28 kB)\n",
            "  Downloading google_cloud_core-1.6.0-py2.py3-none-any.whl (28 kB)\n",
            "  Downloading google_cloud_core-1.5.0-py2.py3-none-any.whl (27 kB)\n",
            "  Downloading google_cloud_core-1.4.4-py2.py3-none-any.whl (27 kB)\n",
            "  Downloading google_cloud_core-1.4.3-py2.py3-none-any.whl (27 kB)\n",
            "INFO: pip is looking at multiple versions of google-cloud-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading google_cloud_core-1.4.2-py2.py3-none-any.whl (26 kB)\n",
            "  Downloading google_cloud_core-1.4.1-py2.py3-none-any.whl (26 kB)\n",
            "  Downloading google_cloud_core-1.4.0-py2.py3-none-any.whl (26 kB)\n",
            "  Downloading google_cloud_core-1.3.0-py2.py3-none-any.whl (26 kB)\n",
            "  Downloading google_cloud_core-1.2.0-py2.py3-none-any.whl (26 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "  Downloading google_cloud_core-1.1.0-py2.py3-none-any.whl (26 kB)\n",
            "  Downloading google_cloud_core-1.0.3-py2.py3-none-any.whl (26 kB)\n",
            "INFO: pip is looking at multiple versions of google-cloud-bigquery to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-cloud-bigquery<3.0.0dev,>=1.15.0\n",
            "  Downloading google_cloud_bigquery-2.34.3-py2.py3-none-any.whl (206 kB)\n",
            "\u001b[K     |████████████████████████████████| 206 kB 41.0 MB/s \n",
            "\u001b[?25hCollecting google-cloud-core<3.0.0dev,>=1.4.1\n",
            "  Downloading google_cloud_core-2.3.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting google-resumable-media<3.0dev,>=0.6.0\n",
            "  Downloading google_resumable_media-2.3.3-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform==1.7.1) (2.8.2)\n",
            "Collecting google-crc32c<2.0dev,>=1.0\n",
            "  Downloading google_crc32c-1.3.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-cloud-aiplatform==1.7.1) (3.0.9)\n",
            "Collecting protobuf<4.0.0dev,>=3.12.0\n",
            "  Downloading protobuf-3.20.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (2022.5.18.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<3.0.0dev,>=1.26.0->google-cloud-aiplatform==1.7.1) (1.24.3)\n",
            "Installing collected packages: protobuf, google-crc32c, proto-plus, google-resumable-media, google-cloud-core, google-cloud-storage, google-cloud-bigquery, google-cloud-aiplatform\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.17.3\n",
            "    Uninstalling protobuf-3.17.3:\n",
            "      Successfully uninstalled protobuf-3.17.3\n",
            "  Attempting uninstall: google-resumable-media\n",
            "    Found existing installation: google-resumable-media 0.4.1\n",
            "    Uninstalling google-resumable-media-0.4.1:\n",
            "      Successfully uninstalled google-resumable-media-0.4.1\n",
            "  Attempting uninstall: google-cloud-core\n",
            "    Found existing installation: google-cloud-core 1.0.3\n",
            "    Uninstalling google-cloud-core-1.0.3:\n",
            "      Successfully uninstalled google-cloud-core-1.0.3\n",
            "  Attempting uninstall: google-cloud-storage\n",
            "    Found existing installation: google-cloud-storage 1.18.1\n",
            "    Uninstalling google-cloud-storage-1.18.1:\n",
            "      Successfully uninstalled google-cloud-storage-1.18.1\n",
            "  Attempting uninstall: google-cloud-bigquery\n",
            "    Found existing installation: google-cloud-bigquery 1.21.0\n",
            "    Uninstalling google-cloud-bigquery-1.21.0:\n",
            "      Successfully uninstalled google-cloud-bigquery-1.21.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "pandas-gbq 0.13.3 requires google-cloud-bigquery[bqstorage,pandas]<2.0.0dev,>=1.11.1, but you have google-cloud-bigquery 2.34.3 which is incompatible.\n",
            "google-cloud-translate 1.5.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.3.0 which is incompatible.\n",
            "google-cloud-firestore 1.7.0 requires google-cloud-core<2.0dev,>=1.0.3, but you have google-cloud-core 2.3.0 which is incompatible.\n",
            "google-cloud-datastore 1.8.0 requires google-cloud-core<2.0dev,>=1.0.0, but you have google-cloud-core 2.3.0 which is incompatible.\u001b[0m\n",
            "Successfully installed google-cloud-aiplatform-1.7.1 google-cloud-bigquery-2.34.3 google-cloud-core-2.3.0 google-cloud-storage-1.44.0 google-crc32c-1.3.0 google-resumable-media-2.3.3 proto-plus-1.20.5 protobuf-3.20.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting google-cloud-pipeline-components==0.2.0\n",
            "  Downloading google_cloud_pipeline_components-0.2.0-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-cloud-aiplatform>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from google-cloud-pipeline-components==0.2.0) (1.7.1)\n",
            "Collecting google-cloud-notebooks>=0.4.0\n",
            "  Downloading google_cloud_notebooks-1.3.2-py2.py3-none-any.whl (354 kB)\n",
            "\u001b[K     |████████████████████████████████| 354 kB 50.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-core<2dev,>=1.26.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-pipeline-components==0.2.0) (1.31.6)\n",
            "Collecting kfp<2.0.0,>=1.8.9\n",
            "  Downloading kfp-1.8.12.tar.gz (301 kB)\n",
            "\u001b[K     |████████████████████████████████| 301 kB 42.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<2.0dev,>=1.25.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (1.35.0)\n",
            "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (3.20.1)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (21.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (1.15.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (2022.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (1.56.2)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.25.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (4.8)\n",
            "Requirement already satisfied: proto-plus>=1.10.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components==0.2.0) (1.20.5)\n",
            "Requirement already satisfied: google-cloud-bigquery<3.0.0dev,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components==0.2.0) (2.34.3)\n",
            "Requirement already satisfied: google-cloud-storage<2.0.0dev,>=1.32.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components==0.2.0) (1.44.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.29.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (1.46.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components==0.2.0) (2.3.3)\n",
            "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components==0.2.0) (2.8.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components==0.2.0) (2.3.0)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery<3.0.0dev,>=1.15.0->google-cloud-aiplatform>=1.4.3->google-cloud-pipeline-components==0.2.0) (1.3.0)\n",
            "Requirement already satisfied: absl-py<2,>=0.9 in /usr/local/lib/python3.7/dist-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (1.0.0)\n",
            "Collecting PyYAML<6,>=5.3\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 52.4 MB/s \n",
            "\u001b[?25hCollecting kubernetes<19,>=8.0.0\n",
            "  Downloading kubernetes-18.20.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 40.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-api-python-client<2,>=1.7.8 in /usr/local/lib/python3.7/dist-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (1.12.11)\n",
            "Collecting requests-toolbelt<1,>=0.8.0\n",
            "  Downloading requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.1 MB/s \n",
            "\u001b[?25hCollecting cloudpickle<3,>=2.0.0\n",
            "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
            "Collecting kfp-server-api<2.0.0,>=1.1.2\n",
            "  Downloading kfp-server-api-1.8.1.tar.gz (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.8 MB/s \n",
            "\u001b[?25hCollecting jsonschema<4,>=3.0.1\n",
            "  Downloading jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tabulate<1,>=0.8.6 in /usr/local/lib/python3.7/dist-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (0.8.9)\n",
            "Requirement already satisfied: click<9,>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (7.1.2)\n",
            "Collecting Deprecated<2,>=1.2.7\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting strip-hints<1,>=0.1.8\n",
            "  Downloading strip-hints-0.1.10.tar.gz (29 kB)\n",
            "Collecting docstring-parser<1,>=0.7.3\n",
            "  Downloading docstring_parser-0.14.1-py3-none-any.whl (33 kB)\n",
            "Collecting kfp-pipeline-spec<0.2.0,>=0.1.14\n",
            "  Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl (19 kB)\n",
            "Collecting fire<1,>=0.3.1\n",
            "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: uritemplate<4,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (3.0.1)\n",
            "Collecting pydantic<2,>=1.8.2\n",
            "  Downloading pydantic-1.9.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 38.8 MB/s \n",
            "\u001b[?25hCollecting typer<1.0,>=0.3.2\n",
            "  Downloading typer-0.4.1-py3-none-any.whl (27 kB)\n",
            "Collecting typing-extensions<4,>=3.7.4\n",
            "  Downloading typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated<2,>=1.2.7->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (1.14.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire<1,>=0.3.1->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (1.1.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.7.8->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (0.0.4)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.7.8->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (0.17.4)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (0.18.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (21.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (4.11.4)\n",
            "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.7/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (2022.5.18.1)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.7/dist-packages (from kubernetes<19,>=8.0.0->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (1.3.1)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=1.25.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.26.0->google-cloud-pipeline-components==0.2.0) (2.10)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from strip-hints<1,>=0.1.8->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (0.37.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema<4,>=3.0.1->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp<2.0.0,>=1.8.9->google-cloud-pipeline-components==0.2.0) (3.2.0)\n",
            "Building wheels for collected packages: kfp, fire, kfp-server-api, strip-hints\n",
            "  Building wheel for kfp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kfp: filename=kfp-1.8.12-py3-none-any.whl size=419048 sha256=291da965569e3a1abffc8ffbbe2db9c6bea88005224f9d45a000267338a2faa3\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/0c/4a/3fc55077bc88cc17eacaae34c5fd3f6178c1d16d2ee3b0afdf\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=46dcc6c8661795951b63b999259661fea93ae0b3d72789448d0b615dde02776f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
            "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.1-py3-none-any.whl size=95549 sha256=64b19ba319d0f88b1d77a7bdb24c5fd98000a9bd7ad0e1c109032fb77d8dc316\n",
            "  Stored in directory: /root/.cache/pip/wheels/f5/4e/2e/6795bd3ed456a43652e7de100aca275ec179c9a8dfbcc65626\n",
            "  Building wheel for strip-hints (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for strip-hints: filename=strip_hints-0.1.10-py2.py3-none-any.whl size=22302 sha256=2e17fb1ceeaefbd22297fbddd2b50da5a8c3e48a8f107e763f23119a83e18736\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/14/c3/6e44e9b2545f2d570b03f5b6d38c00b7534aa8abb376978363\n",
            "Successfully built kfp fire kfp-server-api strip-hints\n",
            "Installing collected packages: typing-extensions, websocket-client, PyYAML, typer, strip-hints, requests-toolbelt, pydantic, kubernetes, kfp-server-api, kfp-pipeline-spec, jsonschema, fire, docstring-parser, Deprecated, cloudpickle, kfp, google-cloud-notebooks, google-cloud-pipeline-components\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.2.0\n",
            "    Uninstalling typing-extensions-4.2.0:\n",
            "      Successfully uninstalled typing-extensions-4.2.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: jsonschema\n",
            "    Found existing installation: jsonschema 4.3.3\n",
            "    Uninstalling jsonschema-4.3.3:\n",
            "      Successfully uninstalled jsonschema-4.3.3\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "nbclient 0.6.4 requires jupyter-client>=6.1.5, but you have jupyter-client 5.3.5 which is incompatible.\n",
            "nbclient 0.6.4 requires traitlets>=5.2.2, but you have traitlets 5.1.1 which is incompatible.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Deprecated-1.2.13 PyYAML-5.4.1 cloudpickle-2.1.0 docstring-parser-0.14.1 fire-0.4.0 google-cloud-notebooks-1.3.2 google-cloud-pipeline-components-0.2.0 jsonschema-3.2.0 kfp-1.8.12 kfp-pipeline-spec-0.1.16 kfp-server-api-1.8.1 kubernetes-18.20.0 pydantic-1.9.1 requests-toolbelt-0.9.1 strip-hints-0.1.10 typer-0.4.1 typing-extensions-3.10.0.2 websocket-client-1.3.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google",
                  "typing_extensions"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting kfp==1.8.8\n",
            "  Downloading kfp-1.8.8.tar.gz (296 kB)\n",
            "\u001b[K     |████████████████████████████████| 296 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting absl-py<=0.11,>=0.9\n",
            "  Downloading absl_py-0.11.0-py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 48.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML<6,>=5.3 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (5.4.1)\n",
            "Requirement already satisfied: google-cloud-storage<2,>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (1.44.0)\n",
            "Requirement already satisfied: kubernetes<19,>=8.0.0 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (18.20.0)\n",
            "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (1.12.11)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.1 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (1.35.0)\n",
            "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (0.9.1)\n",
            "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (2.1.0)\n",
            "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (1.8.1)\n",
            "Requirement already satisfied: jsonschema<4,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (3.2.0)\n",
            "Requirement already satisfied: tabulate<1,>=0.8.6 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (0.8.9)\n",
            "Requirement already satisfied: click<9,>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (7.1.2)\n",
            "Requirement already satisfied: Deprecated<2,>=1.2.7 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (1.2.13)\n",
            "Requirement already satisfied: strip-hints<1,>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (0.1.10)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (0.14.1)\n",
            "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.13 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (0.1.16)\n",
            "Requirement already satisfied: fire<1,>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (0.4.0)\n",
            "Requirement already satisfied: protobuf<4,>=3.13.0 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (3.20.1)\n",
            "Requirement already satisfied: uritemplate<4,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (3.0.1)\n",
            "Requirement already satisfied: pydantic<2,>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (1.9.1)\n",
            "Requirement already satisfied: typer<1.0,>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (0.4.1)\n",
            "Requirement already satisfied: typing-extensions<4,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from kfp==1.8.8) (3.10.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py<=0.11,>=0.9->kfp==1.8.8) (1.15.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated<2,>=1.2.7->kfp==1.8.8) (1.14.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire<1,>=0.3.1->kfp==1.8.8) (1.1.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.8) (0.0.4)\n",
            "Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.8) (1.31.6)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client<2,>=1.7.8->kfp==1.8.8) (0.17.4)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp==1.8.8) (57.4.0)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp==1.8.8) (2.23.0)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp==1.8.8) (21.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp==1.8.8) (1.56.2)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp==1.8.8) (2022.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.1->kfp==1.8.8) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.1->kfp==1.8.8) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.1->kfp==1.8.8) (0.2.8)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2,>=1.20.0->kfp==1.8.8) (2.3.0)\n",
            "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from google-cloud-storage<2,>=1.20.0->kfp==1.8.8) (2.3.3)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.7/dist-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp==1.8.8) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp==1.8.8) (4.11.4)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp==1.8.8) (21.4.0)\n",
            "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema<4,>=3.0.1->kfp==1.8.8) (0.18.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.8) (2.8.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.8) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3>=1.15 in /usr/local/lib/python3.7/dist-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp==1.8.8) (1.24.3)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.7/dist-packages (from kubernetes<19,>=8.0.0->kfp==1.8.8) (1.3.2)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.7/dist-packages (from kubernetes<19,>=8.0.0->kfp==1.8.8) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp==1.8.8) (3.0.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp==1.8.8) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp==1.8.8) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client<2,>=1.7.8->kfp==1.8.8) (2.10)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from strip-hints<1,>=0.1.8->kfp==1.8.8) (0.37.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->jsonschema<4,>=3.0.1->kfp==1.8.8) (3.8.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp==1.8.8) (3.2.0)\n",
            "Building wheels for collected packages: kfp\n",
            "  Building wheel for kfp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kfp: filename=kfp-1.8.8-py3-none-any.whl size=409608 sha256=004fa005a34a51d3118c4ff048ad994bd0ffb3922f170f0f2c5a520142cc28a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/34/19/0e8d16ff7e8c3dbcb65b66cad4a9db4d6d9c0c3d469b16e003\n",
            "Successfully built kfp\n",
            "Installing collected packages: absl-py, kfp\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.0.0\n",
            "    Uninstalling absl-py-1.0.0:\n",
            "      Successfully uninstalled absl-py-1.0.0\n",
            "  Attempting uninstall: kfp\n",
            "    Found existing installation: kfp 1.8.12\n",
            "    Uninstalling kfp-1.8.12:\n",
            "      Successfully uninstalled kfp-1.8.12\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.2+zzzcolab20220527125636 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.1 which is incompatible.\n",
            "google-cloud-pipeline-components 0.2.0 requires kfp<2.0.0,>=1.8.9, but you have kfp 1.8.8 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.11.0 kfp-1.8.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtTT_nZzevNK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DJyao5kfylbI"
      },
      "source": [
        "**Please restart yor Colab runtime before importing the modules**\n",
        "\n",
        "Otherwise you might get a version conflict related error. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mcs7B5VUox_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181afb5a-ffc0-4a93-a99d-08028b5ff84b"
      },
      "source": [
        "import kfp\n",
        "\n",
        "from typing import NamedTuple\n",
        "\n",
        "from kfp.v2.dsl import pipeline\n",
        "from kfp.v2.dsl import component\n",
        "from kfp.v2.dsl import OutputPath\n",
        "from kfp.v2.dsl import InputPath\n",
        "\n",
        "from kfp.v2.dsl import Output\n",
        "from kfp.v2.dsl import Metrics\n",
        "\n",
        "from kfp.v2 import compiler\n",
        "from kfp.v2.google.client import AIPlatformClient\n",
        "\n",
        "\n",
        "from google.cloud import aiplatform\n",
        "from google.cloud.aiplatform import pipeline_jobs\n",
        "\n",
        "from google_cloud_pipeline_components import aiplatform as gcc_aip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L21RLrfDFdcE"
      },
      "source": [
        "# Authentication"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0RNBXMlf3Gl",
        "outputId": "3f74c99d-83d8-4feb-8bb0-4f7a6e6ae4ed"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "credentials = auth._check_adc()\n",
        "print(credentials)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google.colab.auth:Failure refreshing credentials: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Enginemetadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7faa54229d10>)\n",
            "INFO:google.colab.auth:Failure refreshing credentials: (\"Failed to retrieve http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/?recursive=true from the Google Compute Enginemetadata service. Status: 404 Response:\\nb''\", <google.auth.transport.requests._Response object at 0x7faa5420d4d0>)\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGReMEivS070"
      },
      "source": [
        "set the project id"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYz_UaJ1S0QX"
      },
      "source": [
        "PROJECT_ID = \"sascha-playground-doit\"\n",
        "PIPELINE_ROOT = \"gs://doit-vertex-demo/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pD8XJufeSDAm"
      },
      "source": [
        "# Clients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v5AkYzaFb3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff56b306-0f22-455f-8acf-d80da658f4e7"
      },
      "source": [
        "# Deprecated don't use this anymore\n",
        "#from kfp.v2.google.client import AIPlatformClient\n",
        "api_client = AIPlatformClient(project_id=PROJECT_ID,\n",
        "                              region='us-central1')\n",
        "\n",
        "# use this instead\n",
        "aiplatform.init(project=PROJECT_ID,\n",
        "                location='us-central1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/client.py:173: FutureWarning: AIPlatformClient will be deprecated in v2.0.0. Please use PipelineJob https://googleapis.dev/python/aiplatform/latest/_modules/google/cloud/aiplatform/pipeline_jobs.html in Vertex SDK. Install the SDK using \"pip install google-cloud-aiplatform\"\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCSPjj-D4Fao"
      },
      "source": [
        "# Pipeline Basic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gyZkv8xyenN"
      },
      "source": [
        "## Components"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onddQwd1U1qR"
      },
      "source": [
        "@component() \n",
        "def concat(a: str, b: str) -> str:\n",
        "  return a + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma7xWwLLVSlr"
      },
      "source": [
        "@component\n",
        "def reverse(a: str)->NamedTuple(\"outputs\", [(\"before\", str), (\"after\", str)]):\n",
        "  return a, a[::-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZxMEEIWygAg"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUrZade1VZGy"
      },
      "source": [
        "@pipeline(name=\"basic-pipeline\",\n",
        "          pipeline_root=PIPELINE_ROOT + \"basic-pipeline\")\n",
        "def basic_pipeline(a: str='stres', b: str='sed'):\n",
        "    concat_task = concat(a, b)\n",
        "    reverse_task = reverse(concat_task.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTL5tzhSXRpG"
      },
      "source": [
        "## Compile\n",
        "\n",
        "The compiler takes our pipeline function and compiles it into our pipeline specifiction as json file. This json file we can use to create our pipeline in Vertex AI Pipelines."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF0r0-CwVgpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6382ee9-2eba-432b-d7ef-cb92c697a2b5"
      },
      "source": [
        "compiler.Compiler().compile(\n",
        "pipeline_func=basic_pipeline, package_path=\"basic_pipeline.json\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4_93MkF369u"
      },
      "source": [
        "## Run\n",
        "\n",
        "Create the run job using the API. \n",
        "You can also directly upload the pipeline JSON file in the Vertx AI UI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwlXs0reY56x"
      },
      "source": [
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"basic-pipeline\",\n",
        "    template_path=\"basic_pipeline.json\",\n",
        "    parameter_values={\"a\": \"stres\", \"b\": \"sed\"}\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aogrQzmBZs7T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6b434cb-69fb-49a6-dde7-68692d6fafcb"
      },
      "source": [
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFlc7P5BTstS"
      },
      "source": [
        "# Is There More? I Want to Learn the Honest Stuff."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veJ5zQOxSqPJ"
      },
      "source": [
        "## Component Specification (function based component)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1zyzD1-Ssi2"
      },
      "source": [
        "@component(output_component_file=\"concat_component.yaml\") \n",
        "def concat(a: str, b: str) -> str:\n",
        "  return a + b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzHM-vQ2T82E",
        "outputId": "a664f1d6-3459-47b4-bb22-d678f4b80bca"
      },
      "source": [
        "!cat ./concat_component.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: Concat\n",
            "inputs:\n",
            "- {name: a, type: String}\n",
            "- {name: b, type: String}\n",
            "outputs:\n",
            "- {name: Output, type: String}\n",
            "implementation:\n",
            "  container:\n",
            "    image: python:3.7\n",
            "    command:\n",
            "    - sh\n",
            "    - -c\n",
            "    - |2\n",
            "\n",
            "      if ! [ -x \"$(command -v pip)\" ]; then\n",
            "          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\n",
            "      fi\n",
            "\n",
            "      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.8' && \"$0\" \"$@\"\n",
            "    - sh\n",
            "    - -ec\n",
            "    - |\n",
            "      program_path=$(mktemp -d)\n",
            "      printf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n",
            "      python3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "    - |2+\n",
            "\n",
            "      import kfp\n",
            "      from kfp.v2 import dsl\n",
            "      from kfp.v2.dsl import *\n",
            "      from typing import *\n",
            "\n",
            "      def concat(a: str, b: str) -> str:\n",
            "        return a + b\n",
            "\n",
            "    args:\n",
            "    - --executor_input\n",
            "    - {executorInput: null}\n",
            "    - --function_to_execute\n",
            "    - concat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIqsDew7Yn1o"
      },
      "source": [
        "## Share components\n",
        "In this example we use the component specification created based on a function based component."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AW-PsUmPYuFo"
      },
      "source": [
        "@pipeline(name=\"share-component\", \n",
        "          pipeline_root=PIPELINE_ROOT + \"share-component-pipeine\")\n",
        "def share_component_pipeline(a: str='stres', b: str='sed'):\n",
        "    #concat_op = concat(a, b)\n",
        "    concat_component = kfp.components.load_component_from_file('./concat_component.yaml')\n",
        "\n",
        "    concat_task = concat_component(a,b)\n",
        "    reverse_task = reverse(concat_task.output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmW81e_WZ1mZ",
        "outputId": "297edb29-f0fe-4ad7-f5e6-ae6eac1876ed"
      },
      "source": [
        "# just the usual boilerplate code to run the pipeline\n",
        "compiler.Compiler().compile(\n",
        "  pipeline_func=share_component_pipeline, package_path=\"share_component_pipeline.json\"\n",
        ")\n",
        "\n",
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"share-component-pipeline\",\n",
        "    template_path=\"share_component_pipeline.json\",\n",
        "    parameter_values={\"a\": \"stres\", \"b\": \"sed\"}\n",
        ")\n",
        "\n",
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPKvcwXX4KDe"
      },
      "source": [
        "## Pipeline with GPU and machine type"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxntLJgD4l45"
      },
      "source": [
        "The following is an example how you can add an GPU to your component. For example the training componentn that needs access to accelerators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3v231zyV4MUO"
      },
      "source": [
        "@component(output_component_file=\"gpu_training.yaml\", \n",
        "           base_image=\"gcr.io/deeplearning-platform-release/tf2-gpu.2-6\") \n",
        "def gpuTrainingFunc() -> bool:\n",
        "  import logging\n",
        "  import tensorflow as tf\n",
        "\n",
        "  gpus = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "  for gpu in gpus:\n",
        "    logging.info('Name: {} Type: {}'.format(gpu.name, gpu.device_type))\n",
        "  \n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sN_qYZE-6Nfn"
      },
      "source": [
        "@pipeline(name=\"gpu-pipeline\",\n",
        "          pipeline_root=PIPELINE_ROOT + \"gpu-pipeline\")\n",
        "def gpu_pipeline():\n",
        "    gpuTraining = gpuTrainingFunc().add_node_selector_constraint(\n",
        "        label_name=\"cloud.google.com/gke-accelerator\", \n",
        "        value=\"NVIDIA_TESLA_T4\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRXVqzdi7rdD",
        "outputId": "6b7c4998-ad88-4f09-ffc1-2da9b7845a83"
      },
      "source": [
        "compiler.Compiler().compile(\n",
        "  pipeline_func=gpu_pipeline, package_path=\"gpu_pipeline.json\"\n",
        ")\n",
        "\n",
        "job = pipeline_jobs.PipelineJob(\n",
        "   display_name=\"gpu-pipeline\",\n",
        "   template_path=\"gpu_pipeline.json\"\n",
        ")\n",
        "\n",
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZhGKvIO0FKu"
      },
      "source": [
        "## Schedule \n",
        "switch over to GCP and check your Cloud Functions and Cloud Scheduler ;)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YtB-uUp0ILg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4229c2ac-6c99-4de5-94e8-2d855dcde412"
      },
      "source": [
        "from kfp.v2.google.client import AIPlatformClient\n",
        "api_client = AIPlatformClient(project_id=PROJECT_ID, region='us-central1')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/client.py:173: FutureWarning: AIPlatformClient will be deprecated in v2.0.0. Please use PipelineJob https://googleapis.dev/python/aiplatform/latest/_modules/google/cloud/aiplatform/pipeline_jobs.html in Vertex SDK. Install the SDK using \"pip install google-cloud-aiplatform\"\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "QVVt4S130Vrz",
        "outputId": "24e312e3-7a4c-4201-fe07-3d6f3c553752"
      },
      "source": [
        "api_client.create_schedule_from_job_spec(\n",
        "    job_spec_path='basic_pipeline.json',\n",
        "    schedule='*/10 * * * *' # every 10 minutes\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n",
            "WARNING:google.auth._default:No project ID could be determined. Consider running `gcloud config set project` or setting the GOOGLE_CLOUD_PROJECT environment variable\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHttpError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/schedule.py\u001b[0m in \u001b[0;36m_create_from_pipeline_dict\u001b[0;34m(pipeline_dict, schedule, project_id, region, time_zone, parameter_values, pipeline_root, service_account, app_engine_region, cloud_scheduler_service_account)\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0mproject_location_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_location_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mjob_body\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscheduled_job\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/schedule.py\u001b[0m in \u001b[0;36m_create_scheduler_job\u001b[0;34m(project_location_path, job_body)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproject_location_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_body\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m     ).execute()\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googleapiclient/_helpers.py\u001b[0m in \u001b[0;36mpositional_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/googleapiclient/http.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, http, num_retries)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHttpError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muri\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpostproc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHttpError\u001b[0m: <HttpError 409 when requesting https://cloudscheduler.googleapis.com/v1/projects/sascha-playground-doit/locations/us-central1/jobs?alt=json returned \"Job projects/sascha-playground-doit/locations/us-central1/jobs/pipeline_basic-pipeline_9d348449_div10-a-a-a-a already exists.\". Details: \"Job projects/sascha-playground-doit/locations/us-central1/jobs/pipeline_basic-pipeline_9d348449_div10-a-a-a-a already exists.\">",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-adcd945c64a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m api_client.create_schedule_from_job_spec(\n\u001b[1;32m      2\u001b[0m     \u001b[0mjob_spec_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'basic_pipeline.json'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mschedule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'*/10 * * * *'\u001b[0m \u001b[0;31m# every 10 minutes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/client.py\u001b[0m in \u001b[0;36mcreate_schedule_from_job_spec\u001b[0;34m(self, job_spec_path, schedule, time_zone, pipeline_root, parameter_values, service_account, enable_caching, app_engine_region, cloud_scheduler_service_account)\u001b[0m\n\u001b[1;32m    423\u001b[0m             \u001b[0mservice_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mapp_engine_region\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapp_engine_region\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 425\u001b[0;31m             cloud_scheduler_service_account=cloud_scheduler_service_account)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/kfp/v2/google/client/schedule.py\u001b[0m in \u001b[0;36m_create_from_pipeline_dict\u001b[0;34m(pipeline_dict, schedule, project_id, region, time_zone, parameter_values, pipeline_root, service_account, app_engine_region, cloud_scheduler_service_account)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'status'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'409'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m             raise RuntimeError(\n\u001b[0;32m--> 201\u001b[0;31m                 'The exact same schedule already exists') from err\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The exact same schedule already exists"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx9r4CJg2xkY"
      },
      "source": [
        "## Additional Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "al_sL-1f2zYK"
      },
      "source": [
        "@component(packages_to_install = [\"pandas==1.3.4\"],) \n",
        "def additional_packages_missing():\n",
        "  import pandas\n",
        "  print(pandas.__version__)\n",
        "\n",
        "# fails for demonstration purposes\n",
        "@component() \n",
        "def additional_packages():\n",
        "  import pandas\n",
        "  print(pandas.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJl27Itt3iCw",
        "outputId": "6ec78ce1-9cb3-45f5-fdbf-c4bb6eb58fcf"
      },
      "source": [
        "@pipeline(name=\"additional-packages-pipeline\",\n",
        "          pipeline_root=PIPELINE_ROOT + \"additional-packages-pipeline\")\n",
        "def additional_packges_pipeline():\n",
        "    additional_packages_task = additional_packages()\n",
        "    additional_packages_missing_task = additional_packages_missing()\n",
        "\n",
        "compiler.Compiler().compile(\n",
        "  pipeline_func=additional_packges_pipeline, package_path=\"additional_packages_pipeline.json\"\n",
        ")\n",
        "\n",
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"additional-packages-pipeline\",\n",
        "    template_path=\"additional_packages_pipeline.json\"\n",
        ")\n",
        "\n",
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-sEJmKq6msb"
      },
      "source": [
        "## Base Image\n",
        "\n",
        "Compare the component specification yaml and find the difference\n",
        "\n",
        "https://cloud.google.com/vertex-ai/docs/training/pre-built-containers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ1P8F826sjO"
      },
      "source": [
        "@component(output_component_file=\"custom_base_image_component.yaml\",\n",
        "           base_image=\"gcr.io/deeplearning-platform-release/tf2-gpu.2-6\"\n",
        ") \n",
        "def custom_base_image():\n",
        "  import tensorflow as tf\n",
        "  print(tf.version.VERSION)\n",
        "\n",
        "# fails for demonstration purposes\n",
        "@component(output_component_file=\"default_base_image_component.yaml\") \n",
        "def default_base_image():\n",
        "  import tensorflow as tf\n",
        "  print(tf.version.VERSION)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOnGZ59z64Y_",
        "outputId": "27744256-86e8-452e-8efd-2d5037b06810"
      },
      "source": [
        "!cat ./default_base_image_component.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: Default base image\n",
            "implementation:\n",
            "  container:\n",
            "    image: python:3.7\n",
            "    command:\n",
            "    - sh\n",
            "    - -c\n",
            "    - |2\n",
            "\n",
            "      if ! [ -x \"$(command -v pip)\" ]; then\n",
            "          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\n",
            "      fi\n",
            "\n",
            "      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.8' && \"$0\" \"$@\"\n",
            "    - sh\n",
            "    - -ec\n",
            "    - |\n",
            "      program_path=$(mktemp -d)\n",
            "      printf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n",
            "      python3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "    - |2+\n",
            "\n",
            "      import kfp\n",
            "      from kfp.v2 import dsl\n",
            "      from kfp.v2.dsl import *\n",
            "      from typing import *\n",
            "\n",
            "      def default_base_image():\n",
            "        import tensorflow as tf\n",
            "        print(tf.version.VERSION)\n",
            "\n",
            "    args:\n",
            "    - --executor_input\n",
            "    - {executorInput: null}\n",
            "    - --function_to_execute\n",
            "    - default_base_image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9EgmAoq7DAa",
        "outputId": "71a72679-96e5-46cb-9dbc-bd4c30b7b70e"
      },
      "source": [
        "!cat ./custom_base_image_component.yaml"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: Custom base image\n",
            "implementation:\n",
            "  container:\n",
            "    image: gcr.io/deeplearning-platform-release/tf2-gpu.2-6\n",
            "    command:\n",
            "    - sh\n",
            "    - -c\n",
            "    - |2\n",
            "\n",
            "      if ! [ -x \"$(command -v pip)\" ]; then\n",
            "          python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\n",
            "      fi\n",
            "\n",
            "      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'kfp==1.8.8' && \"$0\" \"$@\"\n",
            "    - sh\n",
            "    - -ec\n",
            "    - |\n",
            "      program_path=$(mktemp -d)\n",
            "      printf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\n",
            "      python3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
            "    - |2+\n",
            "\n",
            "      import kfp\n",
            "      from kfp.v2 import dsl\n",
            "      from kfp.v2.dsl import *\n",
            "      from typing import *\n",
            "\n",
            "      def custom_base_image():\n",
            "        import tensorflow as tf\n",
            "        print(tf.version.VERSION)\n",
            "\n",
            "    args:\n",
            "    - --executor_input\n",
            "    - {executorInput: null}\n",
            "    - --function_to_execute\n",
            "    - custom_base_image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JGm1YhnUExE"
      },
      "source": [
        "## Predefined Components\n",
        "\n",
        "For a full list of pre-defined components see https://cloud.google.com/vertex-ai/docs/pipelines/gcpc-list\n",
        "\n",
        "Predefined components depends on the use case.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckZCJavxBtf7"
      },
      "source": [
        "# Pipeline end to end (XGBoost)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCymNXQuW15K"
      },
      "source": [
        "## Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLJqZSzYBu2y"
      },
      "source": [
        "from typing import NamedTuple\n",
        "\n",
        "from kfp.v2 import dsl\n",
        "from kfp.v2.dsl import (Artifact,\n",
        "                        Dataset,\n",
        "                        Input,\n",
        "                        Model,\n",
        "                        Output,\n",
        "                        Metrics,\n",
        "                        ClassificationMetrics,\n",
        "                        component, \n",
        "                        Markdown)\n",
        "\n",
        "from kfp.v2 import compiler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6O8akfmUoWc"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPKVVep2BxU9"
      },
      "source": [
        "@component(\n",
        "    packages_to_install = [\n",
        "        \"pandas==1.3.4\",\n",
        "        \"scikit-learn==1.0.1\",\n",
        "    ],\n",
        ")\n",
        "def get_data(\n",
        "    dataset_train: Output[Dataset],\n",
        "    dataset_test: Output[Dataset],\n",
        "):\n",
        "    \n",
        "    from sklearn import datasets\n",
        "    from sklearn.model_selection import train_test_split as tts\n",
        "    import pandas as pd\n",
        "\n",
        "\n",
        "    # dataset https://www.kaggle.com/uciml/breast-cancer-wisconsin-data\n",
        "    data_raw = datasets.load_breast_cancer()\n",
        "    data = pd.DataFrame(data_raw.data, columns=data_raw.feature_names)\n",
        "    data[\"target\"] = data_raw.target\n",
        "    \n",
        "    train, test = tts(data, test_size=0.3)\n",
        "    \n",
        "    train.to_csv(dataset_train.path)\n",
        "    test.to_csv(dataset_test.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmllUUq0UqDo"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aVHg2lSByxy"
      },
      "source": [
        "@component(\n",
        "    packages_to_install = [\n",
        "        \"pandas==1.3.4\",\n",
        "        \"xgboost==1.5.1\",\n",
        "        \"scikit-learn==1.0.1\", #xgboost requires scikitlearn\n",
        "    ],\n",
        ")\n",
        "def train_model(\n",
        "    dataset: Input[Dataset],\n",
        "    model_artifact: Output[Model]\n",
        "):\n",
        "    \n",
        "    from xgboost import XGBClassifier\n",
        "    import pandas as pd\n",
        "    \n",
        "    data = pd.read_csv(dataset.path)\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        objective=\"binary:logistic\"\n",
        "    )\n",
        "    model.fit(\n",
        "        data.drop(columns=[\"target\"]),\n",
        "        data.target,\n",
        "    )\n",
        "\n",
        "    score = model.score(\n",
        "        data.drop(columns=[\"target\"]),\n",
        "        data.target,\n",
        "    )\n",
        "\n",
        "    model_artifact.metadata[\"train_score\"] = float(score)\n",
        "    model_artifact.metadata[\"framework\"] = \"XGBoost\"\n",
        "\n",
        "    print(model_artifact.path)\n",
        "    \n",
        "    model.save_model(model_artifact.path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkazD35dv0Un"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1AiObLIB1cx"
      },
      "source": [
        "@component(\n",
        "    packages_to_install = [\n",
        "        \"pandas==1.3.4\",\n",
        "        \"scikit-learn==1.0.1\",\n",
        "        \"xgboost==1.5.1\"\n",
        "    ],\n",
        ")\n",
        "def eval_model(\n",
        "    test_set: Input[Dataset],\n",
        "    xgb_model: Input[Model],\n",
        "    metrics: Output[ClassificationMetrics],\n",
        "    smetrics: Output[Metrics]\n",
        ") -> NamedTuple(\"Outputs\", [(\"deploy\", str)]): \n",
        "    from xgboost import XGBClassifier\n",
        "    import pandas as pd\n",
        "    \n",
        "    data = pd.read_csv(test_set.path)\n",
        "    model = XGBClassifier()\n",
        "    model.load_model(xgb_model.path)\n",
        "    \n",
        "    score = model.score(\n",
        "        data.drop(columns=[\"target\"]),\n",
        "        data.target,\n",
        "    )\n",
        "    \n",
        "    from sklearn.metrics import roc_curve\n",
        "    y_scores =  model.predict_proba(data.drop(columns=[\"target\"]))[:, 1]\n",
        "    fpr, tpr, thresholds = roc_curve(\n",
        "         y_true=data.target.to_numpy(), y_score=y_scores, pos_label=True\n",
        "    )\n",
        "    metrics.log_roc_curve(fpr.tolist(), tpr.tolist(), thresholds.tolist())\n",
        "    \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    y_pred = model.predict(data.drop(columns=[\"target\"]))\n",
        "    \n",
        "    metrics.log_confusion_matrix(\n",
        "       [\"False\", \"True\"],\n",
        "       confusion_matrix(\n",
        "           data.target, y_pred\n",
        "       ).tolist()\n",
        "    )\n",
        "    \n",
        "    xgb_model.metadata[\"test_score\"] = float(score)\n",
        "    smetrics.log_metric(\"score\", float(score))\n",
        "\n",
        "\n",
        "    deploy = \"true\"\n",
        "    #compare threshold or to previous\n",
        "\n",
        "    return (deploy,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4qRVZ9Jv2NV"
      },
      "source": [
        "## Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZq-EaJngwFW"
      },
      "source": [
        "@component(packages_to_install=[\"google-cloud-aiplatform==1.3.0\"])\n",
        "def deploy(\n",
        "    model: Input[Model],\n",
        "    project: str,\n",
        "    region: str,):\n",
        "  \n",
        "  import logging\n",
        "  from google.cloud import aiplatform\n",
        "  aiplatform.init(project=project, location=region)\n",
        "\n",
        "  logging.basicConfig(level=logging.DEBUG)\n",
        "  logging.debug(model)\n",
        "\n",
        "  print(model)\n",
        "\n",
        "  import os\n",
        "  path,file = os.path.split(model.uri)\n",
        "\n",
        "  import datetime\n",
        "  \n",
        "  # datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
        "  # serving image https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers#xgboost\n",
        "  deployed_model = aiplatform.Model.upload(\n",
        "        display_name=\"xgboost-pipeline\",\n",
        "        artifact_uri = path,\n",
        "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-4:latest\"\n",
        "  )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRgW9szKv46I"
      },
      "source": [
        "## Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8JS0BA0B7za"
      },
      "source": [
        "@dsl.pipeline(\n",
        "    # Default pipeline root. You can override it when submitting the pipeline.\n",
        "    pipeline_root=PIPELINE_ROOT + \"xgboost-pipeline\",\n",
        "    # A name for the pipeline. Use to determine the pipeline Context.\n",
        "    name=\"xgboost-pipeline-with-deployment\",\n",
        ")\n",
        "def pipeline():\n",
        "    dataset_op = get_data()\n",
        "    training_op = train_model(dataset_op.outputs[\"dataset_train\"])\n",
        "    eval_op = eval_model(\n",
        "        test_set=dataset_op.outputs[\"dataset_test\"],\n",
        "        xgb_model=training_op.outputs[\"model_artifact\"]\n",
        "    )\n",
        "\n",
        "    with dsl.Condition(\n",
        "        eval_op.outputs[\"deploy\"] == \"true\",\n",
        "        name=\"deploy\",\n",
        "    ):\n",
        "      deploy_op = deploy(training_op.outputs[\"model_artifact\"], \n",
        "                         'sascha-playground-doit',\n",
        "                         'us-central1')\n",
        "\n",
        "    # we need a solution for xgb models\n",
        "    # its here https://cloud.google.com/vertex-ai/docs/predictions/deploy-model-api#aiplatform_deploy_model_custom_trained_model_sample-python\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15juxBrzgiLk"
      },
      "source": [
        "## Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfz5joUmghwp",
        "outputId": "de861bb1-01e0-4535-f4ac-b3772dc30677"
      },
      "source": [
        "compiler.Compiler().compile(\n",
        "    pipeline_func=pipeline,\n",
        "    package_path='xgb_pipeline.json')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJL5drQCU3TO"
      },
      "source": [
        "## Run Pipeline (old soon deprectated)\n",
        "deprectation see https://github.com/kubeflow/pipelines/blob/56cf094fd3058b5c640077968ffb0f01e0511a57/sdk/python/kfp/v2/google/client/client.py#L169"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "IS2DvPDSB_FG",
        "outputId": "f8489bd1-9930-4949-c223-f1100d1f4da4"
      },
      "source": [
        "response = api_client.create_run_from_job_spec(\n",
        "    'xgb_pipeline.json',\n",
        "    enable_caching=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/xgboost-pipeline-with-deployment-20211207103057?project=sascha-playground-doit\" target=\"_blank\" >here</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSDY3Rrh8OTq"
      },
      "source": [
        "## Run Pipeline (new)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0g0qJwcG8QHK",
        "outputId": "31448a04-8eef-4cbc-9318-006d4ad373f4"
      },
      "source": [
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"xgb-pipeline\",\n",
        "    template_path=\"xgb_pipeline.json\"\n",
        ")\n",
        "\n",
        "job.run(sync=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wm-Vxnc58cIx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# What about artifacts that are not a dataset or model?\n",
        "\n",
        "For that we can use outputPath which provides similar like the artifacts a path to Google Cloud Storage where we can store data. In any case you need to serialize any intermediate object from memory to save it as a file. In your next component you then can load the serialized file back to in memory object. "
      ],
      "metadata": {
        "id": "hA2zOlhZYBNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@component() \n",
        "def first(output_path: OutputPath()):\n",
        "\n",
        "  # everything that can be serialized to a file can be stored\n",
        "  # you are not limited to the artifact types like dataset or model\n",
        "\n",
        "  # common cases are tfidf\n",
        " \n",
        "  animals = ['cat', 'dog']\n",
        "\n",
        "  import pickle\n",
        "\n",
        "  with open(output_path + \"animals.pkl\", 'wb') as file:\n",
        "    pickle.dump(animals, file)"
      ],
      "metadata": {
        "id": "1KWS9ZQyYL00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@component() \n",
        "def second(input_path: InputPath()):\n",
        "\n",
        "  import pickle\n",
        "  file = open(input_path + \"animals.pkl\", 'rb')\n",
        "  data = pickle.load(file)\n",
        "  file.close()\n",
        "\n",
        "  print(data)"
      ],
      "metadata": {
        "id": "S1EKc_9rYWHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@pipeline(name=\"output-path-pipeline\",\n",
        "          pipeline_root=PIPELINE_ROOT + \"output-path-pipeline\")\n",
        "def output_pipeline():\n",
        "    first_task = first()\n",
        "    second_task = second(first_task.output)"
      ],
      "metadata": {
        "id": "ApQ80C7IaeiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compiler.Compiler().compile(\n",
        "  pipeline_func=output_pipeline, package_path=\"output_pipeline.json\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtBerMSaa1UG",
        "outputId": "2988a385-3811-409b-e4b0-adfb5e7684f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/kfp/v2/compiler/compiler.py:1266: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
            "  category=FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job = pipeline_jobs.PipelineJob(\n",
        "    display_name=\"output-pipeline\",\n",
        "    template_path=\"output_pipeline.json\"\n",
        ")"
      ],
      "metadata": {
        "id": "7SmXK6aAbWdc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job.run(sync=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aWXapX6btqp",
        "outputId": "89893fc8-4f33-4c4d-82e7-d90f9c7051fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "31_R3lA-bxNq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}