{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "946d3c07",
   "metadata": {},
   "source": [
    "# API call from NSRDB for multiple location for multiple year and save locally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421eba33",
   "metadata": {},
   "source": [
    "### Create a folder where you would like to save the weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8536444",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://developer.nrel.gov/api/nsrdb/v2/solar/psm3-download.csv?api_key=D3m04m2UNPQTXU81Yjq9aBfhAhw7IXQRdOjaIygu\"\n",
    "\n",
    "headers = {\n",
    "    'content-type': \"application/x-www-form-urlencoded\",\n",
    "    'cache-control': \"no-cache\"\n",
    "}\n",
    "\n",
    "for year in range(2010, 2019):\n",
    "    for location in [\"37.335480+-121.893028\",\"37.266949+-122.025146\",\"37.386051+-122.083855\",\"37.2350+-121.9570\",\"37.3172+-122.0385\"]:\n",
    "        payload = \"names=\" + str(year) + \"&reason=Academic&mailing_list=true&interval=30&utc=false&email=ritanjali.jena@sjsu.edu&leap_day=false&n=NREL&wkt=POINT(\" + location + \")\"\n",
    "        response = requests.request(\"POST\", url, data=payload, headers=headers)\n",
    "        \n",
    "        #create a folder in local and give that path here\n",
    "        file_name = \"/Users/ritu/Downloads/apidemoraw/weather_\" + str(year) + \"_\" + location + \".csv\"\n",
    "        \n",
    "        f = open(file_name, \"a\")\n",
    "        f.write(response.text)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b9a21",
   "metadata": {},
   "source": [
    "# Combine all file into single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2a3b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "#Give your file path here\n",
    "os.chdir(\"/Users/ritu/Downloads/apidemoraw\")\n",
    "\n",
    "extension = 'csv'\n",
    "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "#combine all files in the list\n",
    "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
    "\n",
    "#export to csv, rename your file name\n",
    "combined_csv.to_csv( \"allraw_combined.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c1541",
   "metadata": {},
   "source": [
    "# Data Pre-Process Code: Combine Hour and Minute, Dropping columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0bbfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def read_data(data_paths):\n",
    "    \"\"\"Read the data files and combine them into a single dataset.\n",
    "    Args:\n",
    "        data_paths (list): Strings of the paths to the data files.\n",
    "    Returns:\n",
    "        A single NumPy array consisting of the data from all datasets\n",
    "    \"\"\"\n",
    "    # Read the first data file\n",
    "    first_path = data_paths[0]\n",
    "    full_data = np.genfromtxt(first_path, delimiter=',', skip_header=2,\n",
    "            names=True)\n",
    "\n",
    "    # Append all remaining data files\n",
    "    num_files = len(data_paths)\n",
    "    for i in range(1, num_files):\n",
    "        path = data_paths[i]\n",
    "        new_data = np.genfromtxt(path, delimiter=',', skip_header=2,\n",
    "                names=True)\n",
    "        full_data = np.hstack((full_data, new_data))\n",
    "\n",
    "    return full_data\n",
    "\n",
    "def trim_vars(data):\n",
    "    \"\"\"Trim extraneous variables and observations from the data.\n",
    "    Args:\n",
    "        data (ndarray): The full unprocessed dataset\n",
    "    Returns:\n",
    "        The full dataset with extraneous variables and observations\n",
    "        trimmed off.\n",
    "    \"\"\"\n",
    "    # Remove all columns with names in `rm_vars`\n",
    "    rm_vars = ['Unnamed: 0','DHI', 'DNI', 'Clearsky_DHI', 'Clearsky_DNI',\n",
    "            'Clearsky_GHI', 'Fill_Flag','Global_Horizontal_UV_Irradiance_280400nm','Global_Horizontal_UV_Irradiance_295385nm', 'f0', 'f1',\n",
    "       'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'f10', 'f11', 'f12',\n",
    "       'f13', 'f14', 'f15', 'f16', 'f17', 'f18', 'f19', 'f20']\n",
    "    var_names = list(data.dtype.names)\n",
    "    var_names\n",
    "    keep_vars = [_ for _ in var_names if _ not in rm_vars]\n",
    "    #print(\"keep_vars\")\n",
    "    #print(keep_vars)\n",
    "    data_trimmed = data[keep_vars]\n",
    "    return data_trimmed\n",
    "\n",
    "def recode_time(data):\n",
    "    \"\"\"Recode the 'Hour' column to encapsulate both the hour and the\n",
    "    minute, and then remove the 'Minute' column.\n",
    "    Args:\n",
    "        data (ndarray): The full unprocessed dataset\n",
    "    Returns:\n",
    "        The full dataset with extraneous variables and observations\n",
    "    \"\"\"\n",
    "    # Recode 'Hour'\n",
    "    data['Hour'] = data['Hour'] + data['Minute'] / 60\n",
    "\n",
    "    # Remove 'Minute'\n",
    "    var_names = list(data.dtype.names)\n",
    "    keep_vars = [_ for _ in var_names if _ != 'Minute']\n",
    "    \n",
    "    data_trimmed = data[:, keep_vars]\n",
    "    return data_trimmed\n",
    "\n",
    "def read_and_preprocess():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    data_paths = ['/Users/ritu/Downloads/cupertino_test/cupertino_test.csv']\n",
    "    dat = read_data(data_paths)\n",
    "    dat = trim_vars(dat)\n",
    "    #print(\"printing\")\n",
    "    #print(dat)\n",
    "\n",
    "    return dat\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d0e20bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(2020.,  1.,  1.,  0.,  0., 9. , 7.,  9. , 0., 100.  , 165.51, 0.13, 1023., 1.1, 282., 1.4, 117546.),\n",
       "       (2020.,  1.,  1.,  0., 30., 9.3, 7.,  9.3, 0., 100.  , 165.16, 0.13, 1023., 1.1, 278., 1.3, 117546.),\n",
       "       (2020.,  1.,  1.,  1.,  0., 9.6, 7.,  9.6, 0., 100.  , 162.29, 0.13, 1023., 1.2, 274., 1.1, 117546.),\n",
       "       ...,\n",
       "       (2019., 12., 31., 22., 30., 4. , 0., -0.1, 0.,  74.4 , 153.97, 0.13, 1021., 0.3,  27., 2.2, 117546.),\n",
       "       (2019., 12., 31., 23.,  0., 3.7, 0., -0.7, 0.,  72.72, 159.03, 0.13, 1021., 0.3,  29., 2.1, 117546.),\n",
       "       (2019., 12., 31., 23., 30., 3.4, 0., -0.7, 0.,  74.27, 163.15, 0.13, 1021., 0.3,  29., 2. , 117546.)],\n",
       "      dtype={'names': ['Year', 'Month', 'Day', 'Hour', 'Minute', 'Temperature', 'Cloud_Type', 'Dew_Point', 'GHI', 'Relative_Humidity', 'Solar_Zenith_Angle', 'Surface_Albedo', 'Pressure', 'Precipitable_Water', 'Wind_Direction', 'Wind_Speed', 'Location'], 'formats': ['<f8', '<f8', '<f8', '<f8', '<f8', '<f8', '<f8', '<f8', '<f8', '<f8', '<f8', '<f8', '<f8', '<f8', '<f8', '<f8', '<f8'], 'offsets': [0, 8, 16, 24, 32, 40, 72, 80, 112, 120, 128, 136, 144, 152, 160, 168, 192], 'itemsize': 368})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "read_and_preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0f064ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to save cleaned and processed combine datafile in local system\n",
    "import pandas as pd \n",
    "\n",
    "#Give the location path here where you wiould like to save the file\n",
    "pd.DataFrame(read_and_preprocess()).to_csv(\"//Users/ritu/Downloads/apidemoraw/all_cities_transformed_combined.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ff1144",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
